# **Proyecto de ETL: Limpieza y An√°lisis Inicial de Churn - Challenge Alura ONE (Parte 1)**

¬°Bienvenido a la primera fase de mi proyecto de Data Science para Telecom X! Este repositorio documenta el proceso fundamental de **ETL (Extracci√≥n, Transformaci√≥n y Carga)**, donde convert√≠ datos crudos y complejos en un dataset limpio y listo para el an√°lisis.

- **Autor:** Gonzalo Malca Garcia
- **Programa:** Oracle Next Education (ONE) + Alura Latam
- **Tecnolog√≠as Clave:** Python, Pandas, Seaborn, Google Colab

---

### **üéØ El Reto: Poniendo Orden en el Caos**

La empresa **Telecom X** me encomend√≥ una misi√≥n crucial: investigar por qu√© estaban perdiendo tantos clientes. Sin embargo, antes de poder responder a esa pregunta, me enfrent√© a un desaf√≠o com√∫n en el mundo real: los datos no estaban listos.

Mi objetivo en esta primera etapa fue:
1.  **Conectarme** a la fuente de datos original (una API JSON).
2.  **Limpiar, estructurar y validar** la informaci√≥n.
3.  **Realizar un primer an√°lisis exploratorio** para obtener los primeros insights.
4.  **Generar un dataset de alta calidad** que sirviera como base para futuros modelos predictivos.

---

### **üõ†Ô∏è Mi Metodolog√≠a: Un Pipeline de ETL Detallado**

Para asegurar la integridad de los datos, implement√© un pipeline de ETL paso a paso:

1.  **Extracci√≥n (`Extract`):**
    *   Me conect√© a una API para obtener los datos de los clientes en formato **JSON**, que ven√≠an en una estructura anidada.

2.  **Transformaci√≥n (`Transform`):**
    *   **Aplanado de Datos:** Utilic√© la funci√≥n `pd.json_normalize()` para convertir la compleja estructura JSON en una tabla plana y manejable de 21 columnas.
    *   **Diagn√≥stico de Calidad:** Us√© `.info()` y `.isnull().sum()` para realizar un chequeo completo, descubriendo un tipo de dato incorrecto en la columna de cargos totales.
    *   **Limpieza de Datos Num√©ricos:** Convert√≠ la columna `account.Charges.Total` a formato num√©rico y elimin√© 11 filas que conten√≠an valores no v√°lidos.
    *   **Limpieza de Datos Categ√≥ricos:** Identifiqu√© y elimin√© 24 registros que ten√≠an un valor inconsistente ("fantasma") en la columna `Churn` mediante el uso de `.str.strip()`.
    *   **Enriquecimiento de Datos:** Cre√© una nueva columna, `customer.Charges.Daily`, para obtener una visi√≥n m√°s granular del gasto de los clientes.

3.  **Carga (`Load`):**
    *   El resultado final del pipeline es el archivo **`telecom_x_datos_limpios.csv`**, un dataset con **7,032 registros de clientes y 22 columnas**, completamente limpio y listo para el an√°lisis.

---

### **üîé Primeros Hallazgos: Las Pistas Iniciales**

El an√°lisis exploratorio sobre el dataset limpio revel√≥ una **tasa de Churn del 26.58%** y nos dio las primeras pistas sobre los perfiles de riesgo:
*   **Servicio de Internet:** El plan de **Fibra √ìptica** muestra una tasa de cancelaci√≥n alarmantemente alta.
*   **Antig√ºedad:** Los **clientes nuevos** son los m√°s propensos a cancelar.
*   **Servicios Adicionales:** La falta de **Soporte T√©cnico y Seguridad Online** est√° fuertemente correlacionada con el Churn.

---


### **üíª Archivos en este Repositorio**

1.  **`Solucion_Challenge_ETL_GMG.ipynb`:** El notebook de Google Colab con todo el c√≥digo del proceso ETL y el an√°lisis.


---

### **üë®‚Äçüíª Desarrollado por**

**Gonzalo Malca Garcia**

